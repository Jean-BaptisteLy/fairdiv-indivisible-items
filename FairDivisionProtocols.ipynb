{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Protocols for Fair Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import Problem\n",
    "import fairness_measures\n",
    "#import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several protocols have been implemented. They can be accessed by importing the module protocols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 8, 'r5': 1}\n",
      "agent 2{'r0': 2, 'r1': 3, 'r2': 9, 'r3': 1, 'r4': 2, 'r5': 3}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p0 = Problem(3,6,'empty', centralized=True)\n",
    "p0.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':8,'r5':1},\\\n",
    "{'r0':2,'r1':3,'r2':9,'r3':1,'r4':2,'r5':3}])\n",
    "print (p0)\n",
    "print (p0.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0.322, 'r1': 0.087, 'r2': 0.301, 'r3': 0.29}\n",
      "agent 2{'r0': 0.353, 'r1': 0.151, 'r2': 0.092, 'r3': 0.403}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1 = Problem(3,4,'normalized',centralized=True)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r3', 'r4']\t11\n",
      "agent  2           ['r0', 'r1', 'r2', 'r5']\t17\n",
      "\n",
      "[(1.5, 'r1'), (2.0, 'r0'), (1.8, 'r2'), (3.0, 'r5')]\n",
      "Resource  r1  moves from  2  to  1\n",
      "Resource  r2  will be splitted!\n",
      "Agent  1  gets  0.071  of resource  r2\n",
      "Both agents get utility: 13.355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13.355, 0.07142857142857142)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.adjustedWinner(p0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you understand exactly why items are allocated this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Manipulating Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 74, 'r1': 26}\n",
      "agent 2{'r0': 75, 'r1': 25}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2 = Problem(3,2,'uniform',centralized=True)\n",
    "p2.setUtilities(\n",
    "[{'r0':0,'r1':0},\\\n",
    "{'r0':74,'r1':26},\\\n",
    "{'r0':75,'r1':25}]\n",
    ")\n",
    "print (p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, the output of the adjusted winner protocol is rather obvious. Each agent gets its preferred item and everyone enjoys 75 of utility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                             ['r1']\t26\n",
      "agent  2                             ['r0']\t75\n",
      "\n",
      "[(1.014, 'r0')]\n",
      "Resource  r0  will be splitted!\n",
      "Agent  1  gets  0.329  of resource  r0\n",
      "Both agents get utility: 50.346000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50.346000000000004, 0.3288590604026846)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.adjustedWinner(p2,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can you find a **manipulation** for agent 1, that is, a way to misrepresent the preferences of the agent (in other words, announce a valuation for an item which differs from the real one) such that the utility is in reality higher? \n",
    "Note that you will need to compute the allocation with the **declared** preferences, but that the actual utility enjoyed by agents must be computed with their **true** preferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"best\" manipulation that agent 1 can do? \n",
    "To evaluate this, it will be useful to run a script trying all the different values possibly announced by agent 1, and to plot the utility obtained with each of these. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 2 Picking Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3 = Problem(4,6,'empty', centralized=True)\n",
    "p3.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print (p3)\n",
    "print (p3.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us apply a picking sequence on our problem p3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  1  picks  r4\n",
      "agent  2  picks  r2\n",
      "agent  3  picks  r0\n",
      "agent  2  picks  r1\n",
      "agent  3  picks  r3\n",
      "agent  1  picks  r5\n"
     ]
    }
   ],
   "source": [
    "s0 = [1,2,3,2,3,1]\n",
    "protocols.pickingSequence(p3,s0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctioneer                                  []\t\n",
      "agent  1                       ['r4', 'r5']\t 9\n",
      "agent  2                       ['r2', 'r1']\t14\n",
      "agent  3                       ['r0', 'r3']\t 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p3.printAllocation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(fairness_measures.envyMatrix(p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to generate standard sequences, like balanced or alternate ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the fairest picking sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider 3 agents and 5 items. Can you propose some sequence which would do well in terms of egalitarian social welfare? You can simulate a number of picking sequences by specifying: the number of experiments, the number of agents (remember to count agent 0 here-to be fixed sorry), the number of objects, the sequence, and the ways utilities are generated.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                   5.0\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.301\n",
      "= Average number of envious:             0.761\n",
      "= Average max envy:                       1.05\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,3,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                   5.0\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.297\n",
      "= Average number of envious:             0.777\n",
      "= Average max envy:                      1.024\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,2,3,3,2],'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to conclude: \n",
    "For 3 agents, and 6 and 8 objects, could you find the fairest picking sequences in terms of: \n",
    "* egalitarian social welfare\n",
    "* average max envy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 agents and 6 objects :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 7.604\n",
      "= Ratio of proportional:                 0.79\n",
      "= Ratio of envy free:                    0.503\n",
      "= Average number of envious:             0.588\n",
      "= Average max envy:                      1.453\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,6,[1,1,3,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 8.341\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.752\n",
      "= Average number of envious:             0.273\n",
      "= Average max envy:                      0.309\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# good sequence\n",
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)\n",
    "simulations.simulationPickingSequences(1000,4,6,s,'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 agents and 8 objects :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.415\n",
      "= Ratio of proportional:                0.895\n",
      "= Ratio of envy free:                    0.548\n",
      "= Average number of envious:             0.487\n",
      "= Average max envy:                      1.079\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,1,2,3,1,2],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.892\n",
      "= Ratio of proportional:                0.965\n",
      "= Ratio of envy free:                    0.719\n",
      "= Average number of envious:              0.29\n",
      "= Average max envy:                       0.58\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# good sequence\n",
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,3,2,1,2,3],'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Lipton et al. protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now test the protocol of Lipton, which allocates items one by one and solves envy cycles when they occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 2{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 3{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Running the Lipton et al. protocol\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: []}\n",
      "allocating resource  r0\n",
      "auctioneer      ['r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [1], 3: [1]}\n",
      "allocating resource  r1\n",
      "auctioneer            ['r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r2\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                             ['r2']\t 4\n",
      "\n",
      "envy graph: {0: [], 1: [2, 3], 2: [3], 3: [1]}\n",
      "solving the cycle: []\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r1']\t 2\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "allocating resource  r3\n",
      "auctioneer                        ['r4', 'r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: [1]}\n",
      "allocating resource  r4\n",
      "auctioneer                              ['r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r5\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "Final allocation:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                       ['r0', 'r5']\t 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Problem(4,6,'empty','centralized')\n",
    "print(p4)\n",
    "print(p4.printAllocation())\n",
    "p4.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print(p4)\n",
    "\n",
    "protocols.lipton(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Local deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us play a bit with local exchanges. For this, we will need to create a decentralized MARA problem. Items are intially allocated at random among agents. Here, utilities are Borda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 6, 'r1': 2, 'r2': 1, 'r3': 4, 'r4': 3, 'r5': 5}\n",
      "agent 1{'r0': 4, 'r1': 6, 'r2': 1, 'r3': 3, 'r4': 5, 'r5': 2}\n",
      "agent 2{'r0': 6, 'r1': 3, 'r2': 1, 'r3': 2, 'r4': 5, 'r5': 4}\n",
      "agent 3{'r0': 6, 'r1': 5, 'r2': 1, 'r3': 2, 'r4': 3, 'r5': 4}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                 ['r0', 'r1', 'r4']\t11\n",
      "agent  1                             ['r3']\t 3\n",
      "agent  2                             ['r2']\t 1\n",
      "agent  3                             ['r5']\t 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p5 = Problem(4,6,'borda',centralized=False)\n",
    "print(p5)\n",
    "print(p5.printAllocation())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot which agents could perform mutually beneficial deals? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  2  meets agent  3\n",
      "deal between  2  and  3 for  r0  and  r1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r5']\t 5\n",
      "agent  1                             ['r2']\t 3\n",
      "agent  2                 ['r3', 'r4', 'r1']\t15\n",
      "agent  3                             ['r0']\t 6\n",
      "\n",
      "agent  0  meets agent  3\n",
      "agent  1  meets agent  3\n",
      "agent  0  meets agent  2\n",
      "agent  0  meets agent  1\n",
      "deal between  0  and  1 for  r5  and  r2\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r2']\t 6\n",
      "agent  1                             ['r5']\t 4\n",
      "agent  2                 ['r3', 'r4', 'r1']\t15\n",
      "agent  3                             ['r0']\t 6\n",
      "\n",
      "agent  0  meets agent  1\n",
      "agent  2  meets agent  3\n",
      "agent  1  meets agent  3\n",
      "agent  1  meets agent  2\n",
      "agent  0  meets agent  3\n",
      "agent  0  meets agent  2\n",
      "End of dynamics. No more deal possible.\n"
     ]
    }
   ],
   "source": [
    "protocols.randomDynamics(p5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the envy of the final allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [2], 1: [2], 2: [], 3: [2]}\n"
     ]
    }
   ],
   "source": [
    "m = fairness_measures.envyMatrix(p5)\n",
    "g = fairness_measures.buildEnvyGraph(m)\n",
    "print (g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Could you find fairer dynamics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, agents just meet randomly (a given pair is picked uniformly among the possible ones). \n",
    "Could you conceive a fairer dynamics and test it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: BT protocol with contested pile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code the BT protocol, and return the size of the contested pile, the Borda score of agents as well as whether the allocation is EF under the definition seen during the course. When increasing the number of objects, plot the likelihood of the protocol returning an EF allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BT_name_prefered_items(p):\n",
    "    preferences_A = p.agent[0].u.copy()\n",
    "    preferences_B = p.agent[1].u.copy()\n",
    "    preferences_A = list(dict(sorted(preferences_A.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    preferences_B = list(dict(sorted(preferences_B.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    return preferences_A,preferences_B\n",
    "\n",
    "def BT_allocation(preferences_A, preferences_B):\n",
    "    contested_pile = []\n",
    "    A = []\n",
    "    B = []\n",
    "    while(True):\n",
    "        if preferences_A[0] != preferences_B[0]:\n",
    "            A.append(preferences_A[0])\n",
    "            B.append(preferences_B[0])\n",
    "            if preferences_B[0] in preferences_A:\n",
    "                preferences_A.remove(preferences_B[0])\n",
    "            if preferences_A[0] in preferences_B:\n",
    "                preferences_B.remove(preferences_A[0])\n",
    "        else:\n",
    "            contested_pile.append(preferences_A[0])\n",
    "            \n",
    "        preferences_A.remove(preferences_A[0])\n",
    "        preferences_B.remove(preferences_B[0])\n",
    "        if len(preferences_A) == 0 and len(preferences_B) == 0:\n",
    "            break  \n",
    "    return A,B,contested_pile\n",
    "\n",
    "def BT_protocol(p):\n",
    "    \n",
    "    preferences_A, preferences_B = BT_name_prefered_items(p)\n",
    "    #print(\"Preferences A :\",preferences_A)\n",
    "    #print(\"Preferences B :\",preferences_B)\n",
    "    \n",
    "    bundle_A, bundle_B, contested_pile = BT_allocation(preferences_A.copy(), preferences_B.copy())\n",
    "    #print(\"Bundle A :\",bundle_A)\n",
    "    #print(\"Bundle B :\",bundle_B)\n",
    "    #print(\"Contested pile :\",contested_pile)\n",
    "    \n",
    "    # convert bundles to allocations\n",
    "    bundles = [bundle_A,bundle_B]\n",
    "    allocation = []\n",
    "    for i in range(len(p.agent)):\n",
    "        allocation.append([0]*p.m)\n",
    "        for j in range(len(bundles[i])):\n",
    "            allocation[i][int(bundles[i][j][-1])] = 1\n",
    "    \n",
    "    p.setAllocation(allocation)\n",
    "    #print(p.printAllocation())\n",
    "    \n",
    "    size_contested_pile = len(contested_pile)\n",
    "\n",
    "    # borda score\n",
    "    borda_score = []\n",
    "    preferences = [preferences_A, preferences_B]\n",
    "    for i in range(len(p.agent)):\n",
    "        borda_score.append(0)\n",
    "        for j in range(len(bundles[i])):\n",
    "            borda_score[-1] += len(preferences[i]) - preferences[i].index(bundles[i][j])\n",
    "    \n",
    "    em = fairness_measures.envyMatrix(p)\n",
    "    #print(em)\n",
    "    #print(\"There are \", fairness_measures.nbEnviousAgents(em), \" envious agents\")\n",
    "    #print(\"The maximum envy among two agents is \", fairness_measures.maxEnvy(em))\n",
    "    is_EF = fairness_measures.isEnvyFree(em)\n",
    "    \n",
    "    return size_contested_pile, borda_score[0], borda_score[1], is_EF\n",
    "\n",
    "def plot_likelihood(nb_objects,nb_iterations):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(1,nb_objects):\n",
    "        cpt = 0\n",
    "        for j in range(nb_iterations):\n",
    "            p = Problem(2,i,'borda',centralized=False)\n",
    "            size_contested_pile, borda_score_a, borda_score_b, is_EF = BT_protocol(p)\n",
    "            if is_EF:\n",
    "                cpt += 1\n",
    "        x.append(i)\n",
    "        y.append(cpt/100)\n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 2, 'r1': 3, 'r2': 6, 'r3': 5, 'r4': 1, 'r5': 4}\n",
      "agent 1{'r0': 2, 'r1': 4, 'r2': 5, 'r3': 6, 'r4': 1, 'r5': 3}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                 ['r0', 'r2', 'r3']\t13\n",
      "agent  1                 ['r1', 'r4', 'r5']\t 8\n",
      "\n",
      "(2, 10, 10, True)\n"
     ]
    }
   ],
   "source": [
    "p_bt = Problem(2,6,'borda',centralized=False)\n",
    "print(p_bt)\n",
    "print(p_bt.printAllocation())\n",
    "\n",
    "temp = BT_protocol(p_bt)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nb_objects = 50\n",
    "nb_iterations = 100\n",
    "x,y = plot_likelihood(nb_objects,nb_iterations)\n",
    "\n",
    "plt.title(\"Evolution\")\n",
    "plt.xlabel(\"Number of objects\")\n",
    "plt.ylabel(\"% envy-free\")\n",
    "plt.plot(x, y, c=\"green\", label=\"\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 4], [2, 5], [3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "\n",
    "# Example 2 :\n",
    "A = [1, 2, 3, 4]\n",
    "B = [2, 3, 4, 1]\n",
    "\n",
    "# Example 3 :\n",
    "A = [1, 2, 3, 4, 5, 6]\n",
    "B = [2, 3, 5, 4, 1, 6]\n",
    "\n",
    "\n",
    "print(BT_allocation(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The discussion and example about Adjusted Winner Manipulation is taken from a video by Eric Pacuit: \n",
    "https://www.youtube.com/watch?v=RtcnSXL69NQ\n",
    "\n",
    "* See (Bouveret and Lang, IJCAI-11) for more details about picking sequences. \n",
    "\n",
    "* See https://www.ams.org/notices/201402/rnoti-p130.pdf for the description of the BT protocol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notebook last updated 2022-01-17"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
