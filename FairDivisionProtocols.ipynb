{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Protocols for Fair Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import Problem\n",
    "import fairness_measures\n",
    "#import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several protocols have been implemented. They can be accessed by importing the module protocols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 8, 'r5': 1}\n",
      "agent 2{'r0': 2, 'r1': 3, 'r2': 9, 'r3': 1, 'r4': 2, 'r5': 3}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p0 = Problem(3,6,'empty', centralized=True)\n",
    "p0.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':8,'r5':1},\\\n",
    "{'r0':2,'r1':3,'r2':9,'r3':1,'r4':2,'r5':3}])\n",
    "print (p0)\n",
    "print (p0.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0.322, 'r1': 0.087, 'r2': 0.301, 'r3': 0.29}\n",
      "agent 2{'r0': 0.353, 'r1': 0.151, 'r2': 0.092, 'r3': 0.403}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1 = Problem(3,4,'normalized',centralized=True)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r3', 'r4']\t11\n",
      "agent  2           ['r0', 'r1', 'r2', 'r5']\t17\n",
      "\n",
      "[(1.5, 'r1'), (2.0, 'r0'), (1.8, 'r2'), (3.0, 'r5')]\n",
      "Resource  r1  moves from  2  to  1\n",
      "Resource  r2  will be splitted!\n",
      "Agent  1  gets  0.071  of resource  r2\n",
      "Both agents get utility: 13.355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13.355, 0.07142857142857142)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.adjustedWinner(p0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you understand exactly why items are allocated this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Manipulating Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 74, 'r1': 26}\n",
      "agent 2{'r0': 75, 'r1': 25}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2 = Problem(3,2,'uniform',centralized=True)\n",
    "p2.setUtilities(\n",
    "[{'r0':0,'r1':0},\\\n",
    "{'r0':74,'r1':26},\\\n",
    "{'r0':75,'r1':25}]\n",
    ")\n",
    "print (p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, the output of the adjusted winner protocol is rather obvious. Each agent gets its preferred item and everyone enjoys 75 of utility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                             ['r1']\t26\n",
      "agent  2                             ['r0']\t75\n",
      "\n",
      "[(1.014, 'r0')]\n",
      "Resource  r0  will be splitted!\n",
      "Agent  1  gets  0.329  of resource  r0\n",
      "Both agents get utility: 50.346000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50.346000000000004, 0.3288590604026846)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.adjustedWinner(p2,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can you find a **manipulation** for agent 1, that is, a way to misrepresent the preferences of the agent (in other words, announce a valuation for an item which differs from the real one) such that the utility is in reality higher? \n",
    "Note that you will need to compute the allocation with the **declared** preferences, but that the actual utility enjoyed by agents must be computed with their **true** preferences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"best\" manipulation that agent 1 can do? \n",
    "To evaluate this, it will be useful to run a script trying all the different values possibly announced by agent 1, and to plot the utility obtained with each of these. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 2 Picking Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3 = Problem(4,6,'empty', centralized=True)\n",
    "p3.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print (p3)\n",
    "print (p3.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us apply a picking sequence on our problem p3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  1  picks  r4\n",
      "agent  2  picks  r2\n",
      "agent  3  picks  r0\n",
      "agent  2  picks  r1\n",
      "agent  3  picks  r3\n",
      "agent  1  picks  r5\n"
     ]
    }
   ],
   "source": [
    "s0 = [1,2,3,2,3,1]\n",
    "protocols.pickingSequence(p3,s0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctioneer                                  []\t\n",
      "agent  1                       ['r4', 'r5']\t 9\n",
      "agent  2                       ['r2', 'r1']\t14\n",
      "agent  3                       ['r0', 'r3']\t 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p3.printAllocation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(fairness_measures.envyMatrix(p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to generate standard sequences, like balanced or alternate ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the fairest picking sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider 3 agents and 5 items. Can you propose some sequence which would do well in terms of egalitarian social welfare? You can simulate a number of picking sequences by specifying: the number of experiments, the number of agents (remember to count agent 0 here-to be fixed sorry), the number of objects, the sequence, and the ways utilities are generated.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                   5.0\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.301\n",
      "= Average number of envious:             0.761\n",
      "= Average max envy:                       1.05\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,3,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                   5.0\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.297\n",
      "= Average number of envious:             0.777\n",
      "= Average max envy:                      1.024\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,2,3,3,2],'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to conclude: \n",
    "For 3 agents, and 6 and 8 objects, could you find the fairest picking sequences in terms of: \n",
    "* egalitarian social welfare\n",
    "* average max envy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 agents and 6 objects :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 7.604\n",
      "= Ratio of proportional:                 0.79\n",
      "= Ratio of envy free:                    0.503\n",
      "= Average number of envious:             0.588\n",
      "= Average max envy:                      1.453\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,6,[1,1,3,2,2,3],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 8.341\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.752\n",
      "= Average number of envious:             0.273\n",
      "= Average max envy:                      0.309\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# good sequence\n",
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)\n",
    "simulations.simulationPickingSequences(1000,4,6,s,'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 3 agents and 8 objects :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.415\n",
      "= Ratio of proportional:                0.895\n",
      "= Ratio of envy free:                    0.548\n",
      "= Average number of envious:             0.487\n",
      "= Average max envy:                      1.079\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,1,2,3,1,2],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.892\n",
      "= Ratio of proportional:                0.965\n",
      "= Ratio of envy free:                    0.719\n",
      "= Average number of envious:              0.29\n",
      "= Average max envy:                       0.58\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# good sequence\n",
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,3,2,1,2,3],'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Lipton et al. protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now test the protocol of Lipton, which allocates items one by one and solves envy cycles when they occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 2{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 3{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Running the Lipton et al. protocol\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: []}\n",
      "allocating resource  r0\n",
      "auctioneer      ['r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [1], 3: [1]}\n",
      "allocating resource  r1\n",
      "auctioneer            ['r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r2\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                             ['r2']\t 4\n",
      "\n",
      "envy graph: {0: [], 1: [2, 3], 2: [3], 3: [1]}\n",
      "solving the cycle: []\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r1']\t 2\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "allocating resource  r3\n",
      "auctioneer                        ['r4', 'r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: [1]}\n",
      "allocating resource  r4\n",
      "auctioneer                              ['r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r5\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "Final allocation:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                       ['r0', 'r5']\t 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Problem(4,6,'empty','centralized')\n",
    "print(p4)\n",
    "print(p4.printAllocation())\n",
    "p4.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print(p4)\n",
    "\n",
    "protocols.lipton(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Local deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us play a bit with local exchanges. For this, we will need to create a decentralized MARA problem. Items are intially allocated at random among agents. Here, utilities are Borda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 6, 'r1': 2, 'r2': 1, 'r3': 4, 'r4': 3, 'r5': 5}\n",
      "agent 1{'r0': 4, 'r1': 6, 'r2': 1, 'r3': 3, 'r4': 5, 'r5': 2}\n",
      "agent 2{'r0': 6, 'r1': 3, 'r2': 1, 'r3': 2, 'r4': 5, 'r5': 4}\n",
      "agent 3{'r0': 6, 'r1': 5, 'r2': 1, 'r3': 2, 'r4': 3, 'r5': 4}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                 ['r0', 'r1', 'r4']\t11\n",
      "agent  1                             ['r3']\t 3\n",
      "agent  2                             ['r2']\t 1\n",
      "agent  3                             ['r5']\t 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p5 = Problem(4,6,'borda',centralized=False)\n",
    "print(p5)\n",
    "print(p5.printAllocation())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot which agents could perform mutually beneficial deals? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  2  meets agent  3\n",
      "deal between  2  and  3 for  r0  and  r1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r5']\t 5\n",
      "agent  1                             ['r2']\t 3\n",
      "agent  2                 ['r3', 'r4', 'r1']\t15\n",
      "agent  3                             ['r0']\t 6\n",
      "\n",
      "agent  0  meets agent  3\n",
      "agent  1  meets agent  3\n",
      "agent  0  meets agent  2\n",
      "agent  0  meets agent  1\n",
      "deal between  0  and  1 for  r5  and  r2\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                             ['r2']\t 6\n",
      "agent  1                             ['r5']\t 4\n",
      "agent  2                 ['r3', 'r4', 'r1']\t15\n",
      "agent  3                             ['r0']\t 6\n",
      "\n",
      "agent  0  meets agent  1\n",
      "agent  2  meets agent  3\n",
      "agent  1  meets agent  3\n",
      "agent  1  meets agent  2\n",
      "agent  0  meets agent  3\n",
      "agent  0  meets agent  2\n",
      "End of dynamics. No more deal possible.\n"
     ]
    }
   ],
   "source": [
    "protocols.randomDynamics(p5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the envy of the final allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [2], 1: [2], 2: [], 3: [2]}\n"
     ]
    }
   ],
   "source": [
    "m = fairness_measures.envyMatrix(p5)\n",
    "g = fairness_measures.buildEnvyGraph(m)\n",
    "print (g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Could you find fairer dynamics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, agents just meet randomly (a given pair is picked uniformly among the possible ones). \n",
    "Could you conceive a fairer dynamics and test it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: BT protocol with contested pile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code the BT protocol, and return the size of the contested pile, the Borda score of agents as well as whether the allocation is EF under the definition seen during the course. When increasing the number of objects, plot the likelihood of the protocol returning an EF allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BT_name_prefered_items(p):\n",
    "    preferences_A = p.agent[0].u.copy()\n",
    "    preferences_B = p.agent[1].u.copy()\n",
    "    preferences_A = list(dict(sorted(preferences_A.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    preferences_B = list(dict(sorted(preferences_B.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    return preferences_A,preferences_B\n",
    "\n",
    "def BT_allocation(preferences_A, preferences_B):\n",
    "    contested_pile = []\n",
    "    A = []\n",
    "    B = []\n",
    "    while(True):\n",
    "        if preferences_A[0] != preferences_B[0]:\n",
    "            A.append(preferences_A[0])\n",
    "            B.append(preferences_B[0])\n",
    "            if preferences_B[0] in preferences_A:\n",
    "                preferences_A.remove(preferences_B[0])\n",
    "            if preferences_A[0] in preferences_B:\n",
    "                preferences_B.remove(preferences_A[0])\n",
    "        else:\n",
    "            contested_pile.append(preferences_A[0])\n",
    "            \n",
    "        preferences_A.remove(preferences_A[0])\n",
    "        preferences_B.remove(preferences_B[0])\n",
    "        if len(preferences_A) == 0 and len(preferences_B) == 0:\n",
    "            break  \n",
    "    return A,B,contested_pile\n",
    "\n",
    "def BT_protocol(p):\n",
    "    \n",
    "    preferences_A, preferences_B = BT_name_prefered_items(p)\n",
    "    '''print(\"Preferences A :\",preferences_A)\n",
    "    print(\"Preferences B :\",preferences_B)'''\n",
    "    \n",
    "    bundle_A, bundle_B, contested_pile = BT_allocation(preferences_A.copy(), preferences_B.copy())\n",
    "    '''print(\"Bundle A :\",bundle_A)\n",
    "    print(\"Bundle B :\",bundle_B)\n",
    "    print(\"Contested pile :\",contested_pile)'''\n",
    "    \n",
    "    # convert bundles to allocations\n",
    "    bundles = [bundle_A,bundle_B]\n",
    "    allocation = []\n",
    "    for i in range(len(p.agent)):\n",
    "        allocation.append([0]*p.m)\n",
    "        for j in range(len(bundles[i])):\n",
    "            #print(int(bundles[i][j].split(\"r\")[1]))\n",
    "            allocation[i][int(bundles[i][j].split(\"r\")[1])] = 1\n",
    "    \n",
    "    #print(allocation)\n",
    "    p.setAllocation(allocation)\n",
    "    #print(p.printAllocation())\n",
    "    \n",
    "    size_contested_pile = len(contested_pile)\n",
    "\n",
    "    # borda score\n",
    "    borda_score = []\n",
    "    preferences = [preferences_A, preferences_B]\n",
    "    for i in range(len(p.agent)):\n",
    "        borda_score.append(0)\n",
    "        for j in range(len(bundles[i])):\n",
    "            borda_score[-1] += len(preferences[i]) - preferences[i].index(bundles[i][j])\n",
    "    \n",
    "    em = fairness_measures.envyMatrix(p)\n",
    "    #print(em)\n",
    "    #print(\"There are \", fairness_measures.nbEnviousAgents(em), \" envious agents\")\n",
    "    #print(\"The maximum envy among two agents is \", fairness_measures.maxEnvy(em))\n",
    "    is_EF = fairness_measures.isEnvyFree(em)\n",
    "    \n",
    "    return size_contested_pile, borda_score[0], borda_score[1], is_EF\n",
    "\n",
    "def plot_likelihood(nb_objects,nb_iterations):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(1,nb_objects):\n",
    "        cpt = 0\n",
    "        for j in range(nb_iterations):\n",
    "            p = Problem(2,i,'borda',centralized=False)\n",
    "            size_contested_pile, borda_score_a, borda_score_b, is_EF = BT_protocol(p)\n",
    "            if is_EF:\n",
    "                cpt += 1\n",
    "        x.append(i)\n",
    "        y.append(cpt/100)\n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 11, 'r1': 8, 'r10': 19, 'r11': 20, 'r12': 6, 'r13': 7, 'r14': 17, 'r15': 2, 'r16': 3, 'r17': 18, 'r18': 12, 'r19': 10, 'r2': 13, 'r3': 15, 'r4': 4, 'r5': 14, 'r6': 16, 'r7': 5, 'r8': 1, 'r9': 9}\n",
      "agent 1{'r0': 1, 'r1': 13, 'r10': 3, 'r11': 14, 'r12': 20, 'r13': 11, 'r14': 9, 'r15': 6, 'r16': 5, 'r17': 8, 'r18': 2, 'r19': 18, 'r2': 16, 'r3': 15, 'r4': 7, 'r5': 12, 'r6': 19, 'r7': 10, 'r8': 4, 'r9': 17}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0['r1', 'r3', 'r8', 'r9', 'r14', 'r15', 'r17', 'r19']\t80\n",
      "agent  1['r0', 'r2', 'r4', 'r5', 'r6', 'r7', 'r10', 'r11', 'r12', 'r13', 'r16', 'r18']\t120\n",
      "\n",
      "(2, 129, 130, True)\n"
     ]
    }
   ],
   "source": [
    "p_bt = Problem(2,20,'borda',centralized=False)\n",
    "print(p_bt)\n",
    "print(p_bt.printAllocation())\n",
    "\n",
    "temp = BT_protocol(p_bt)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nb_objects = 50\n",
    "nb_iterations = 100\n",
    "x,y = plot_likelihood(nb_objects,nb_iterations)\n",
    "\n",
    "plt.title(\"Evolution\")\n",
    "plt.xlabel(\"Number of objects\")\n",
    "plt.ylabel(\"% envy-free\")\n",
    "plt.plot(x, y, c=\"green\", label=\"\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 4], [2, 5], [3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "\n",
    "# Example 2 :\n",
    "A = [1, 2, 3, 4]\n",
    "B = [2, 3, 4, 1]\n",
    "\n",
    "# Example 3 :\n",
    "A = [1, 2, 3, 4, 5, 6]\n",
    "B = [2, 3, 5, 4, 1, 6]\n",
    "\n",
    "\n",
    "print(BT_allocation(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The discussion and example about Adjusted Winner Manipulation is taken from a video by Eric Pacuit: \n",
    "https://www.youtube.com/watch?v=RtcnSXL69NQ\n",
    "\n",
    "* See (Bouveret and Lang, IJCAI-11) for more details about picking sequences. \n",
    "\n",
    "* See https://www.ams.org/notices/201402/rnoti-p130.pdf for the description of the BT protocol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notebook last updated 2022-01-17"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
